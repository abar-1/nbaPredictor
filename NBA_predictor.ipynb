{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abar-1/nbaPredictor/blob/main/NBA_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRfmNMORFf1J",
        "outputId": "d5b263d5-2ff1-46e2-9df8-fee55162d4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting NBA Stat Predictor...\n",
            "Training seasons: ['2021-22', '2022-23', '2023-24', '2024-25', '2025-26']\n",
            "\n",
            "--- Attempting to auto-detect next game for Domantas Sabonis ---\n",
            "Fetching gamelogs for player 1627734...\n",
            "Found 297 games\n",
            "Fetching next game details (Method 1: PlayerProfile)...\n",
            "Warning: PlayerProfile overview is empty. Getting team from last gamelog.\n",
            "Player's team identified as: SAC (ID: 1610612758)\n",
            "Warning: PlayerProfile shows no upcoming game. Trying scoreboard...\n",
            "Checking scoreboard for 10/31/2025...\n",
            "Checking scoreboard for 11/01/2025...\n",
            "‚úÖ Auto-detected matchup: AWAY vs. MIL\n",
            "‚úÖ Auto-detected rest: 3 days (Last: 2025-10-29, Next: 2025-11-01)\n",
            "Fetching team defensive stats...\n",
            "\n",
            "==================================================\n",
            "Training Model for PTS\n",
            "==================================================\n",
            "Features: 15\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        5.22\n",
            "  Median AE:  4.50\n",
            "  R¬≤:         -0.119\n",
            "  Std Error:  ¬±6.48\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 4.90\n",
            "  Improvement: -6.6%\n",
            "\n",
            "Top 5 Features:\n",
            "  TS_PCT_SEASON_AVG: 0.103\n",
            "  USG_ESTIMATE_SEASON_AVG: 0.098\n",
            "  TS_PCT_ROLL_3_AVG: 0.085\n",
            "  OPP_PACE: 0.079\n",
            "  PTS_ROLL_3_AVG: 0.077\n",
            "\n",
            "==================================================\n",
            "Training Model for REB\n",
            "==================================================\n",
            "Features: 10\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        3.99\n",
            "  Median AE:  2.96\n",
            "  R¬≤:         -0.185\n",
            "  Std Error:  ¬±4.92\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 3.69\n",
            "  Improvement: -8.1%\n",
            "\n",
            "Top 5 Features:\n",
            "  OREB_SEASON_AVG: 0.142\n",
            "  DREB_SEASON_AVG: 0.128\n",
            "  BACK_TO_BACK: 0.117\n",
            "  REB_SEASON_AVG: 0.108\n",
            "  MIN_SEASON_AVG: 0.100\n",
            "\n",
            "==================================================\n",
            "Training Model for AST\n",
            "==================================================\n",
            "Features: 12\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        2.64\n",
            "  Median AE:  2.34\n",
            "  R¬≤:         -0.391\n",
            "  Std Error:  ¬±3.16\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 2.45\n",
            "  Improvement: -8.1%\n",
            "\n",
            "Top 5 Features:\n",
            "  AST_SEASON_AVG: 0.143\n",
            "  AST_ROLL_3_AVG: 0.136\n",
            "  GAME_SCORE_SEASON_AVG: 0.102\n",
            "  AST_SEASON_STD: 0.096\n",
            "  USG_ESTIMATE_SEASON_AVG: 0.091\n",
            "\n",
            "==================================================\n",
            "Training Model for STL\n",
            "==================================================\n",
            "Features: 7\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        0.77\n",
            "  Median AE:  0.78\n",
            "  R¬≤:         -0.222\n",
            "  Std Error:  ¬±0.87\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 0.68\n",
            "  Improvement: -12.9%\n",
            "\n",
            "Top 5 Features:\n",
            "  MIN_SEASON_AVG: 0.173\n",
            "  PF_SEASON_AVG: 0.163\n",
            "  OPP_STL: 0.155\n",
            "  STL_SEASON_AVG: 0.153\n",
            "  BACK_TO_BACK: 0.151\n",
            "\n",
            "==================================================\n",
            "Training Model for BLK\n",
            "==================================================\n",
            "Features: 8\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        0.49\n",
            "  Median AE:  0.44\n",
            "  R¬≤:         0.047\n",
            "  Std Error:  ¬±0.60\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 0.57\n",
            "  Improvement: +13.7%\n",
            "\n",
            "Top 5 Features:\n",
            "  OPP_FGA: 0.157\n",
            "  MIN_SEASON_AVG: 0.152\n",
            "  PF_SEASON_AVG: 0.146\n",
            "  BLK_SEASON_AVG: 0.142\n",
            "  OPP_BLK: 0.142\n",
            "\n",
            "==================================================\n",
            "Training Model for MIN\n",
            "==================================================\n",
            "Features: 10\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        4.82\n",
            "  Median AE:  3.62\n",
            "  R¬≤:         0.042\n",
            "  Std Error:  ¬±6.86\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 4.56\n",
            "  Improvement: -5.5%\n",
            "\n",
            "Top 5 Features:\n",
            "  GAME_SCORE_ROLL_3_AVG: 0.129\n",
            "  PF_SEASON_AVG: 0.122\n",
            "  MIN_SEASON_STD: 0.113\n",
            "  MIN_ROLL_3_AVG: 0.104\n",
            "  OPP_DEF_RATING: 0.103\n",
            "\n",
            "==================================================\n",
            "Training Model for FG3M\n",
            "==================================================\n",
            "Features: 10\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        0.71\n",
            "  Median AE:  0.62\n",
            "  R¬≤:         -0.093\n",
            "  Std Error:  ¬±0.90\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 0.76\n",
            "  Improvement: +7.1%\n",
            "\n",
            "Top 5 Features:\n",
            "  FG3_PCT_SEASON_AVG: 0.132\n",
            "  BACK_TO_BACK: 0.122\n",
            "  FG3A_SEASON_AVG: 0.106\n",
            "  FG3M_SEASON_AVG: 0.105\n",
            "  DAYS_REST: 0.104\n",
            "\n",
            "==================================================\n",
            "Training Model for PRA\n",
            "==================================================\n",
            "Features: 12\n",
            "Training samples: 232 | Test samples: 59\n",
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
            "\n",
            "Model Performance:\n",
            "  MAE:        7.46\n",
            "  Median AE:  5.63\n",
            "  R¬≤:         0.002\n",
            "  Std Error:  ¬±9.85\n",
            "\n",
            "Baseline Comparison:\n",
            "  Season Avg MAE: 7.29\n",
            "  Improvement: -2.3%\n",
            "\n",
            "Top 5 Features:\n",
            "  PRA_SEASON_AVG: 0.111\n",
            "  PRA_ROLL_3_AVG: 0.107\n",
            "  GAME_SCORE_SEASON_AVG: 0.101\n",
            "  PRA_ROLL_7_AVG: 0.095\n",
            "  MIN_SEASON_AVG: 0.094\n",
            "\n",
            "============================================================\n",
            "üéØ PREDICTIONS FOR Domantas Sabonis\n",
            "============================================================\n",
            "Matchup: AWAY vs. MIL (Rest: 3 days)\n",
            "============================================================\n",
            "MIN   | Prediction:  33.1 | 95% CI: [ 19.7,  46.5] | ¬±6.9\n",
            "PRA   | Prediction:  36.4 | 95% CI: [ 17.1,  55.7] | ¬±9.8\n",
            "PTS   | Prediction:  15.4 | 95% CI: [  2.7,  28.1] | ¬±6.5\n",
            "REB   | Prediction:  12.1 | 95% CI: [  2.5,  21.8] | ¬±4.9\n",
            "AST   | Prediction:   5.4 | 95% CI: [  0.0,  11.6] | ¬±3.2\n",
            "STL   | Prediction:   0.6 | 95% CI: [  0.0,   2.3] | ¬±0.9\n",
            "BLK   | Prediction:   0.5 | 95% CI: [  0.0,   1.6] | ¬±0.6\n",
            "FG3M  | Prediction:   0.9 | 95% CI: [  0.0,   2.7] | ¬±0.9\n",
            "============================================================\n",
            "‚úÖ Prediction logged: Domantas Sabonis_20251101\n",
            "\n",
            "============================================================\n",
            "üîß BACKTESTING TOOLS\n",
            "============================================================\n",
            "To update this prediction with actual results after the game:\n",
            "  auto_update_pending_predictions('Domantas Sabonis')\n",
            "\n",
            "To generate accuracy report:\n",
            "  generate_accuracy_report('Domantas Sabonis')\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "üîÑ Checking for pending predictions to update...\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Found 1 pending prediction(s) to update\n",
            "============================================================\n",
            "\n",
            "üîÑ Updating: Domantas Sabonis vs MIL on 2025-11-01\n",
            "Fetching actual stats for Domantas Sabonis on 2025-11-01...\n",
            "Fetching gamelogs for player 1627734...\n",
            "Found 4 games\n",
            "No game found on 2025-11-01\n",
            "‚ö†Ô∏è  Could not fetch actuals for Domantas Sabonis on 2025-11-01\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìä Generating Accuracy Report...\n",
            "============================================================\n",
            "‚ö†Ô∏è  Only 0 completed prediction(s). Need at least 1 for meaningful analysis.\n"
          ]
        }
      ],
      "source": [
        "!pip install nba_api scikit-learn pandas numpy xgboost matplotlib seaborn --quiet\n",
        "\n",
        "print(\"Starting NBA Stat Predictor...\")\n",
        "players = [\"Domantas Sabonis\"]\n",
        "PLAYER_NAME = \"Domantas Sabonis\"\n",
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from nba_api.stats.static import players, teams\n",
        "from nba_api.stats.endpoints import playergamelog, leaguedashteamstats, playerprofilev2, scoreboardv2\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, median_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# --- Constants ---\n",
        "STATS_TO_PREDICT = ['PTS', 'REB', 'AST', 'STL', 'BLK', 'MIN', 'FG3M', 'PRA']\n",
        "\n",
        "# True Shooting constant (free throw factor from NBA)\n",
        "TS_FT_FACTOR = 0.44\n",
        "\n",
        "BASE_PLAYER_FEATURES = [\n",
        "    'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT',\n",
        "    'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL',\n",
        "    'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS',\n",
        "    'TS_PCT', 'GAME_SCORE', 'PRA', 'USG_ESTIMATE'\n",
        "]\n",
        "\n",
        "ROLLING_FEATURES_TO_CALC = ['MIN', 'FGA', 'PTS', 'REB', 'AST', 'PRA', 'GAME_SCORE', 'TS_PCT']\n",
        "\n",
        "OPPONENT_DEFENSE_FEATURES = [\n",
        "    'PTS', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT',\n",
        "    'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK',\n",
        "    'DEF_RATING', 'PACE', 'OPP_EFG_PCT', 'OPP_OREB_PCT', 'OPP_TOV_PCT'\n",
        "]\n",
        "\n",
        "CONTEXT_FEATURES = ['IS_HOME', 'DAYS_REST', 'BACK_TO_BACK']\n",
        "\n",
        "# --- Static Data ---\n",
        "TEAMS_LIST = teams.get_teams()\n",
        "TEAMS_DF = pd.DataFrame(TEAMS_LIST)\n",
        "PLAYERS_LIST = players.get_players()\n",
        "PLAYERS_DF = pd.DataFrame(PLAYERS_LIST)\n",
        "\n",
        "# --- Caching ---\n",
        "CACHE_DIR = \"nba_cache\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def cache_path(filename):\n",
        "    return os.path.join(CACHE_DIR, filename)\n",
        "\n",
        "def save_to_cache(data, filename):\n",
        "    try:\n",
        "        with open(cache_path(filename), \"w\") as f:\n",
        "            json.dump(data, f)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Failed to save cache {filename}: {e}\")\n",
        "\n",
        "def load_from_cache(filename):\n",
        "    try:\n",
        "        with open(cache_path(filename), \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        return None\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def get_player_id(player_name):\n",
        "    player = PLAYERS_DF[PLAYERS_DF['full_name'].str.lower() == player_name.lower()]\n",
        "    return player.iloc[0]['id'] if not player.empty else None\n",
        "\n",
        "def get_team_id(team_abbr):\n",
        "    team = TEAMS_DF[TEAMS_DF['abbreviation'] == team_abbr]\n",
        "    return team.iloc[0]['id'] if not team.empty else None\n",
        "\n",
        "def get_team_abbr(team_id):\n",
        "    team = TEAMS_DF[TEAMS_DF['id'] == team_id]\n",
        "    return team.iloc[0]['abbreviation'] if not team.empty else None\n",
        "\n",
        "def get_training_seasons():\n",
        "    \"\"\"Gets current season and 4 previous seasons.\"\"\"\n",
        "    today = datetime.now()\n",
        "    current_season_start_year = today.year if today.month >= 10 else today.year - 1\n",
        "\n",
        "    seasons = [\n",
        "        f\"{current_season_start_year - i}-{str(current_season_start_year - i + 1)[-2:]}\"\n",
        "        for i in range(4, -1, -1)\n",
        "    ]\n",
        "\n",
        "    print(f\"Training seasons: {seasons}\")\n",
        "    return seasons\n",
        "\n",
        "# --- API Helpers ---\n",
        "def fetch_with_retry_all_dfs(endpoint_class, attempts=3, timeout=15, **kwargs):\n",
        "    for attempt in range(attempts):\n",
        "        try:\n",
        "            time.sleep(0.6)\n",
        "            api_call = endpoint_class(timeout=timeout, **kwargs)\n",
        "            return api_call.get_data_frames()\n",
        "        except Exception as e:\n",
        "            if 'timeout' in str(e).lower() and attempt < attempts - 1:\n",
        "                time.sleep(1)\n",
        "            else:\n",
        "                raise e\n",
        "    raise Exception(f\"Failed to fetch from {endpoint_class.__name__}\")\n",
        "\n",
        "def fetch_with_retry(endpoint_class, attempts=3, timeout=15, **kwargs):\n",
        "    dfs = fetch_with_retry_all_dfs(endpoint_class, attempts, timeout, **kwargs)\n",
        "    return dfs[0] if dfs and len(dfs) > 0 else pd.DataFrame()\n",
        "\n",
        "# --- Data Fetching ---\n",
        "def fetch_player_gamelogs(player_id, seasons):\n",
        "    all_games_df = []\n",
        "    print(f\"Fetching gamelogs for player {player_id}...\")\n",
        "\n",
        "    for season in seasons:\n",
        "        cache_file = f\"player_{player_id}_{season}_gamelog.json\"\n",
        "        cached_data = load_from_cache(cache_file)\n",
        "\n",
        "        df = pd.DataFrame()\n",
        "        if cached_data:\n",
        "            df = pd.DataFrame(cached_data)\n",
        "        else:\n",
        "            try:\n",
        "                df = fetch_with_retry(playergamelog.PlayerGameLog, player_id=player_id, season=season)\n",
        "                if not df.empty:\n",
        "                    save_to_cache(df.to_dict(orient=\"records\"), cache_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Note: Could not fetch {season}\")\n",
        "                df = pd.DataFrame()\n",
        "\n",
        "        if not df.empty:\n",
        "            df['SEASON_ID'] = season\n",
        "            all_games_df.append(df)\n",
        "\n",
        "    if not all_games_df:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    full_df = pd.concat(all_games_df, ignore_index=True)\n",
        "    full_df['GAME_DATE'] = pd.to_datetime(full_df['GAME_DATE'])\n",
        "    full_df = full_df.sort_values(by='GAME_DATE').reset_index(drop=True)\n",
        "\n",
        "    # --- FIX: Filter out DNP games (where MIN is 0) ---\n",
        "    # This prevents 0-stat games from poisoning the season averages.\n",
        "    full_df = full_df[full_df['MIN'] > 0].reset_index(drop=True)\n",
        "    # --- END FIX ---\n",
        "\n",
        "    print(f\"Found {len(full_df)} games\")\n",
        "    return full_df\n",
        "\n",
        "def fetch_all_team_defensive_stats(seasons):\n",
        "    print(f\"Fetching team defensive stats...\")\n",
        "    season_stats_dict = {}\n",
        "\n",
        "    for season in seasons:\n",
        "        cache_file = f\"team_stats_merged_{season}.json\"\n",
        "        cached_data = load_from_cache(cache_file)\n",
        "\n",
        "        if cached_data:\n",
        "            season_stats_dict[season] = pd.DataFrame(cached_data)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            df_opp = fetch_with_retry(\n",
        "                leaguedashteamstats.LeagueDashTeamStats,\n",
        "                season=season, measure_type_detailed_defense='Opponent', per_mode_detailed='PerGame'\n",
        "            )\n",
        "            df_adv = fetch_with_retry(\n",
        "                leaguedashteamstats.LeagueDashTeamStats,\n",
        "                season=season, measure_type_detailed_defense='Advanced', per_mode_detailed='PerGame'\n",
        "            )\n",
        "            df_four = fetch_with_retry(\n",
        "                leaguedashteamstats.LeagueDashTeamStats,\n",
        "                season=season, measure_type_detailed_defense='Four Factors', per_mode_detailed='PerGame'\n",
        "            )\n",
        "\n",
        "            opp_rename = {\n",
        "                'TEAM_ID': 'TEAM_ID', 'OPP_PTS': 'PTS', 'OPP_FGM': 'FGM', 'OPP_FGA': 'FGA',\n",
        "                'OPP_FG_PCT': 'FG_PCT', 'OPP_FG3M': 'FG3M', 'OPP_FG3A': 'FG3A', 'OPP_FG3_PCT': 'FG3_PCT',\n",
        "                'OPP_FTM': 'FTM', 'OPP_FTA': 'FTA', 'OPP_FT_PCT': 'FT_PCT',\n",
        "                'OPP_OREB': 'OREB', 'OPP_DREB': 'DREB', 'OPP_REB': 'REB',\n",
        "                'OPP_AST': 'AST', 'OPP_TOV': 'TOV', 'OPP_STL': 'STL', 'OPP_BLK': 'BLK'\n",
        "            }\n",
        "            df_opp = df_opp[opp_rename.keys()].rename(columns=opp_rename)\n",
        "            df_adv = df_adv[['TEAM_ID', 'DEF_RATING', 'PACE']]\n",
        "            df_four = df_four[['TEAM_ID', 'OPP_EFG_PCT', 'OPP_OREB_PCT', 'OPP_TOV_PCT']]\n",
        "\n",
        "            df_merged = pd.merge(df_opp, df_adv, on='TEAM_ID')\n",
        "            df_merged = pd.merge(df_merged, df_four, on='TEAM_ID')\n",
        "            df_final = pd.merge(df_merged, TEAMS_DF[['id', 'abbreviation']], left_on='TEAM_ID', right_on='id')\n",
        "            df_final.rename(columns={'abbreviation': 'TEAM_ABBREVIATION'}, inplace=True)\n",
        "            df_final.drop(columns=['id'], inplace=True, errors='ignore')\n",
        "\n",
        "            save_to_cache(df_final.to_dict(orient=\"records\"), cache_file)\n",
        "            season_stats_dict[season] = df_final\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {season}: {e}\")\n",
        "\n",
        "    return season_stats_dict\n",
        "\n",
        "# --- Feature Engineering ---\n",
        "def calculate_advanced_stats(df):\n",
        "    \"\"\"Calculate advanced stats with safety checks.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # True Shooting Percentage\n",
        "    df['TS_PCT'] = df['PTS'] / (2 * (df['FGA'] + TS_FT_FACTOR * df['FTA']) + 1e-6)\n",
        "\n",
        "    # Game Score (John Hollinger's formula)\n",
        "    df['GAME_SCORE'] = (\n",
        "        df['PTS'] + 0.4 * df['FGM'] - 0.7 * df['FGA'] - 0.4 * (df['FTA'] - df['FTM']) +\n",
        "        0.7 * df['OREB'] + 0.3 * df['DREB'] + df['STL'] + 0.7 * df['AST'] +\n",
        "        0.7 * df['BLK'] - 0.4 * df['PF'] - df['TOV']\n",
        "    )\n",
        "\n",
        "    # Points + Rebounds + Assists\n",
        "    df['PRA'] = df['PTS'] + df['REB'] + df['AST']\n",
        "\n",
        "    # Usage estimate (simplified)\n",
        "    df['USG_ESTIMATE'] = (df['FGA'] + 0.44 * df['FTA'] + df['TOV']) / (df['MIN'] + 1e-6)\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_features(player_df, team_stats_dict):\n",
        "    if player_df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = player_df.copy()\n",
        "    df = calculate_advanced_stats(df)\n",
        "\n",
        "    # Target variables (next game stats)\n",
        "    for stat in STATS_TO_PREDICT:\n",
        "        df[f'TARGET_{stat}'] = df[stat].shift(-1)\n",
        "\n",
        "    # Context features\n",
        "    df['IS_HOME'] = (~df['MATCHUP'].str.contains('@')).astype(int)\n",
        "    df['OPP_ABBR'] = df['MATCHUP'].str.split(' ').str[-1]\n",
        "    df['DAYS_REST'] = df['GAME_DATE'].diff().dt.days\n",
        "    df['BACK_TO_BACK'] = (df['DAYS_REST'] == 1).astype(int)\n",
        "\n",
        "    # Season averages and rolling windows\n",
        "    grouped = df.groupby('SEASON_ID')\n",
        "\n",
        "    for stat in BASE_PLAYER_FEATURES:\n",
        "        # Expanding mean (season average up to this point)\n",
        "        df[f'{stat}_SEASON_AVG'] = grouped[stat].transform(lambda x: x.shift(1).expanding().mean())\n",
        "        df[f'{stat}_SEASON_STD'] = grouped[stat].transform(lambda x: x.shift(1).expanding().std())\n",
        "\n",
        "        # Rolling averages for hot/cold streaks\n",
        "        if stat in ROLLING_FEATURES_TO_CALC:\n",
        "            df[f'{stat}_ROLL_3_AVG'] = grouped[stat].transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean())\n",
        "            df[f'{stat}_ROLL_7_AVG'] = grouped[stat].transform(lambda x: x.shift(1).rolling(7, min_periods=3).mean())\n",
        "            df[f'{stat}_ROLL_3_STD'] = grouped[stat].transform(lambda x: x.shift(1).rolling(3, min_periods=1).std())\n",
        "\n",
        "    # Merge opponent defensive stats\n",
        "    all_season_dfs = []\n",
        "    fallback_season = sorted(team_stats_dict.keys())[-1] if team_stats_dict else None\n",
        "\n",
        "    for season_id, group in df.groupby('SEASON_ID'):\n",
        "        team_stats_df = team_stats_dict.get(season_id, team_stats_dict.get(fallback_season))\n",
        "\n",
        "        if team_stats_df is None:\n",
        "            continue\n",
        "\n",
        "        rename_map = {col: f'OPP_{col}' for col in OPPONENT_DEFENSE_FEATURES}\n",
        "        merged_group = pd.merge(\n",
        "            group, team_stats_df.rename(columns=rename_map),\n",
        "            left_on='OPP_ABBR', right_on='TEAM_ABBREVIATION', how='left'\n",
        "        )\n",
        "        all_season_dfs.append(merged_group)\n",
        "\n",
        "    if not all_season_dfs:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    final_df = pd.concat(all_season_dfs, ignore_index=True)\n",
        "\n",
        "    # Clean up\n",
        "    target_cols = [f'TARGET_{stat}' for stat in STATS_TO_PREDICT]\n",
        "    final_df = final_df.dropna(subset=target_cols)\n",
        "\n",
        "    avg_cols = [f'{stat}_SEASON_AVG' for stat in BASE_PLAYER_FEATURES]\n",
        "    final_df = final_df.dropna(subset=avg_cols)\n",
        "    final_df = final_df.fillna(0) # Fill NaNs (rolling std, days_rest)\n",
        "\n",
        "    return final_df\n",
        "\n",
        "def create_prediction_features(player_df, team_stats_dict, next_opp_abbr, is_home, days_rest):\n",
        "    if player_df.empty:\n",
        "        return None\n",
        "\n",
        "    last_game = player_df.iloc[-1]\n",
        "    features = {}\n",
        "\n",
        "    last_game_season = last_game['SEASON_ID']\n",
        "    season_games = player_df[player_df['SEASON_ID'] == last_game_season].copy()\n",
        "    season_games = calculate_advanced_stats(season_games)\n",
        "\n",
        "    # Rolling averages\n",
        "    for stat in ROLLING_FEATURES_TO_CALC:\n",
        "        last_3 = season_games.iloc[-3:][stat]\n",
        "        last_7 = season_games.iloc[-7:][stat]\n",
        "        features[f'{stat}_ROLL_3_AVG'] = last_3.mean()\n",
        "        features[f'{stat}_ROLL_7_AVG'] = last_7.mean()\n",
        "        features[f'{stat}_ROLL_3_STD'] = last_3.std() if len(last_3) > 1 else 0\n",
        "\n",
        "    # Season averages and std\n",
        "    for stat in BASE_PLAYER_FEATURES:\n",
        "        features[f'{stat}_SEASON_AVG'] = season_games[stat].mean()\n",
        "        features[f'{stat}_SEASON_STD'] = season_games[stat].std() if len(season_games) > 1 else 0\n",
        "\n",
        "    # Context\n",
        "    features['IS_HOME'] = int(is_home)\n",
        "    features['DAYS_REST'] = days_rest\n",
        "    features['BACK_TO_BACK'] = int(days_rest == 1)\n",
        "\n",
        "    # Opponent stats\n",
        "    latest_season = player_df['SEASON_ID'].iloc[-1]\n",
        "    opp_stats_df = team_stats_dict.get(latest_season, team_stats_dict[sorted(team_stats_dict.keys())[-1]])\n",
        "\n",
        "    if opp_stats_df is None:\n",
        "        return None\n",
        "\n",
        "    opp_stats = opp_stats_df[opp_stats_df['TEAM_ABBREVIATION'] == next_opp_abbr]\n",
        "\n",
        "    if opp_stats.empty:\n",
        "        print(f\"Warning: No stats for {next_opp_abbr}, using league average\")\n",
        "        opp_stats_avg = opp_stats_df[OPPONENT_DEFENSE_FEATURES].mean()\n",
        "        for col in OPPONENT_DEFENSE_FEATURES:\n",
        "            features[f'OPP_{col}'] = opp_stats_avg.get(col, 0)\n",
        "    else:\n",
        "        for col in OPPONENT_DEFENSE_FEATURES:\n",
        "            features[f'OPP_{col}'] = opp_stats.iloc[0].get(col, 0)\n",
        "\n",
        "    return pd.DataFrame([features]).fillna(0)\n",
        "\n",
        "# --- Enhanced Model Training ---\n",
        "def get_feature_subset(stat_name):\n",
        "    \"\"\"Enhanced feature subsets with new advanced stats.\"\"\"\n",
        "    features = ['IS_HOME', 'DAYS_REST', 'BACK_TO_BACK']\n",
        "\n",
        "    if stat_name != 'MIN':\n",
        "        features.append('MIN_SEASON_AVG')\n",
        "\n",
        "    player_features = {\n",
        "        'PTS': ['PTS_SEASON_AVG', 'PTS_ROLL_3_AVG', 'PTS_ROLL_7_AVG', 'PTS_ROLL_3_STD',\n",
        "                'TS_PCT_SEASON_AVG', 'TS_PCT_ROLL_3_AVG', 'GAME_SCORE_SEASON_AVG',\n",
        "                'FGA_ROLL_3_AVG', 'USG_ESTIMATE_SEASON_AVG'],\n",
        "        'REB': ['REB_SEASON_AVG', 'REB_ROLL_3_AVG', 'REB_SEASON_STD',\n",
        "                'OREB_SEASON_AVG', 'DREB_SEASON_AVG'],\n",
        "        'AST': ['AST_SEASON_AVG', 'AST_ROLL_3_AVG', 'AST_SEASON_STD',\n",
        "                'TOV_SEASON_AVG', 'GAME_SCORE_SEASON_AVG', 'USG_ESTIMATE_SEASON_AVG'],\n",
        "        'STL': ['STL_SEASON_AVG', 'PF_SEASON_AVG'],\n",
        "        'BLK': ['BLK_SEASON_AVG', 'PF_SEASON_AVG'],\n",
        "        'MIN': ['MIN_SEASON_AVG', 'MIN_ROLL_3_AVG', 'MIN_SEASON_STD',\n",
        "                'PF_SEASON_AVG', 'GAME_SCORE_ROLL_3_AVG'],\n",
        "        'FG3M': ['FG3M_SEASON_AVG', 'FG3A_SEASON_AVG', 'FG3M_ROLL_3_AVG',\n",
        "                 'FG3_PCT_SEASON_AVG'],\n",
        "        'PRA': ['PRA_SEASON_AVG', 'PRA_ROLL_3_AVG', 'PRA_ROLL_7_AVG',\n",
        "                'GAME_SCORE_SEASON_AVG', 'GAME_SCORE_ROLL_3_AVG', 'TS_PCT_SEASON_AVG']\n",
        "    }\n",
        "\n",
        "    opp_features = {\n",
        "        'PTS': ['OPP_DEF_RATING', 'OPP_PACE', 'OPP_EFG_PCT'],\n",
        "        'REB': ['OPP_REB', 'OPP_OREB_PCT'],\n",
        "        'AST': ['OPP_AST', 'OPP_TOV_PCT', 'OPP_PACE'],\n",
        "        'STL': ['OPP_STL', 'OPP_TOV_PCT'],\n",
        "        'BLK': ['OPP_BLK', 'OPP_FGA'],\n",
        "        'MIN': ['OPP_DEF_RATING', 'OPP_PACE'],\n",
        "        'FG3M': ['OPP_DEF_RATING', 'OPP_FG3A', 'OPP_FG3_PCT'],\n",
        "        'PRA': ['OPP_DEF_RATING', 'OPP_PACE', 'OPP_EFG_PCT']\n",
        "    }\n",
        "\n",
        "    features.extend(player_features.get(stat_name, []))\n",
        "    features.extend(opp_features.get(stat_name, []))\n",
        "\n",
        "    return list(dict.fromkeys(features)) # Return unique features in order\n",
        "\n",
        "def calculate_baseline_metrics(y_train, y_test):\n",
        "    \"\"\"Calculate simple baseline predictions for comparison.\"\"\"\n",
        "    baselines = {}\n",
        "\n",
        "    # Baseline 1: Season average\n",
        "    season_avg = y_train.mean()\n",
        "    mae_season = mean_absolute_error(y_test, [season_avg] * len(y_test))\n",
        "    baselines['Season Avg'] = {'MAE': mae_season, 'prediction': season_avg}\n",
        "\n",
        "    return baselines\n",
        "\n",
        "def train_model_with_validation(X_all, y, stat_name):\n",
        "    \"\"\"Enhanced training with time-series validation and baselines.\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training Model for {stat_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    feature_subset = get_feature_subset(stat_name)\n",
        "    valid_features = [f for f in feature_subset if f in X_all.columns]\n",
        "    X = X_all[valid_features]\n",
        "\n",
        "    if len(X) < 20:\n",
        "        print(f\"Warning: Only {len(X)} samples. Model may be unreliable.\")\n",
        "        if len(X) < 5:\n",
        "            return None, None, None\n",
        "\n",
        "    # Chronological split\n",
        "    split_idx = int(len(X) * 0.80)\n",
        "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "    # Calculate baselines\n",
        "    baselines = calculate_baseline_metrics(y_train, y_test)\n",
        "\n",
        "    # Simpler param grid for robustness\n",
        "    param_grid = {\n",
        "        'max_depth': [3, 4],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'n_estimators': [100, 150],\n",
        "        'subsample': [0.8],\n",
        "        'colsample_bytree': [0.8]\n",
        "    }\n",
        "\n",
        "    # Use TimeSeriesSplit for proper validation\n",
        "    n_splits = max(2, min(3, len(X_train) // 10)) # At least 10 samples per split\n",
        "\n",
        "    model = None\n",
        "    best_params = {}\n",
        "\n",
        "    if len(X_train) > (n_splits * 5): # Check for enough data for CV\n",
        "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "        xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=xgb, param_grid=param_grid, cv=tscv,\n",
        "            scoring='neg_mean_absolute_error', n_jobs=-1, verbose=0\n",
        "        )\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        model = grid_search.best_estimator_\n",
        "        best_params = grid_search.best_params_\n",
        "    else:\n",
        "        print(\"Warning: Not enough data for TimeSeriesSplit CV. Fitting simple model.\")\n",
        "        model = XGBRegressor(objective='reg:squarederror', random_state=42, max_depth=3, n_estimators=100)\n",
        "        model.fit(X_train, y_train)\n",
        "        best_params = {'max_depth': 3, 'n_estimators': 100} # Default params\n",
        "\n",
        "    # Test metrics\n",
        "    preds = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    medae = median_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "\n",
        "    # Calculate prediction intervals (simple method)\n",
        "    residuals = y_test - preds\n",
        "    std_residual = np.std(residuals)\n",
        "\n",
        "    print(f\"Features: {len(valid_features)}\")\n",
        "    print(f\"Training samples: {len(X_train)} | Test samples: {len(X_test)}\")\n",
        "    print(f\"Best params: {best_params}\")\n",
        "    print(f\"\\nModel Performance:\")\n",
        "    print(f\"  MAE:        {mae:.2f}\")\n",
        "    print(f\"  Median AE:  {medae:.2f}\")\n",
        "    print(f\"  R¬≤:         {r2:.3f}\")\n",
        "    print(f\"  Std Error:  ¬±{std_residual:.2f}\")\n",
        "    print(f\"\\nBaseline Comparison:\")\n",
        "    print(f\"  Season Avg MAE: {baselines['Season Avg']['MAE']:.2f}\")\n",
        "\n",
        "    # --- FIX: Handle baseline_mae == 0 ---\n",
        "    if baselines['Season Avg']['MAE'] == 0:\n",
        "        improvement = 0.0\n",
        "    else:\n",
        "        improvement = ((baselines['Season Avg']['MAE'] - mae) / baselines['Season Avg']['MAE']) * 100\n",
        "    # --- END FIX ---\n",
        "    print(f\"  Improvement: {improvement:+.1f}%\")\n",
        "\n",
        "    # Feature importance\n",
        "    importance = model.feature_importances_\n",
        "    top_features = sorted(zip(valid_features, importance), key=lambda x: x[1], reverse=True)[:5]\n",
        "    print(f\"\\nTop 5 Features:\")\n",
        "    for feat, imp in top_features:\n",
        "        print(f\"  {feat}: {imp:.3f}\")\n",
        "\n",
        "    # Refit on all data\n",
        "    final_model = XGBRegressor(objective='reg:squarederror', random_state=42, **best_params)\n",
        "    final_model.fit(X, y)\n",
        "\n",
        "    metrics = {\n",
        "        'mae': mae, 'medae': medae, 'r2': r2, 'std_error': std_residual,\n",
        "        'baseline_mae': baselines['Season Avg']['MAE'],\n",
        "        'improvement_pct': improvement\n",
        "    }\n",
        "\n",
        "    return final_model, valid_features, metrics\n",
        "\n",
        "# ============================================================================\n",
        "# LOGGING & PREDICTION\n",
        "# ============================================================================\n",
        "\n",
        "def log_prediction_to_csv(player_name, game_date, opponent, is_home, days_rest, predictions):\n",
        "    \"\"\"Saves a prediction record to CSV.\"\"\"\n",
        "    log_file = cache_path(\"prediction_log.csv\")\n",
        "\n",
        "    log_entry = {\n",
        "        'Prediction_ID': f\"{player_name}_{game_date.strftime('%Y%m%d')}\",\n",
        "        'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'Player_Name': player_name,\n",
        "        'Game_Date': game_date.strftime('%Y-%m-%d'),\n",
        "        'Opponent': opponent,\n",
        "        'Matchup': 'HOME' if is_home else 'AWAY',\n",
        "        'Days_Rest': days_rest,\n",
        "        'Status': 'PENDING'\n",
        "    }\n",
        "\n",
        "    # Add predictions with confidence intervals\n",
        "    for stat, pred_data in predictions.items():\n",
        "        if pred_data:\n",
        "            log_entry[f\"Pred_{stat}\"] = pred_data['prediction']\n",
        "            log_entry[f\"Pred_{stat}_Lower\"] = pred_data['lower_95']\n",
        "            log_entry[f\"Pred_{stat}_Upper\"] = pred_data['upper_95']\n",
        "            log_entry[f\"Actual_{stat}\"] = None  # Will be filled later\n",
        "\n",
        "    new_log_df = pd.DataFrame([log_entry])\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(log_file):\n",
        "            log_df = pd.read_csv(log_file)\n",
        "            # Check if prediction already exists\n",
        "            existing = log_df[log_df['Prediction_ID'] == log_entry['Prediction_ID']]\n",
        "            if not existing.empty:\n",
        "                print(f\"‚ö†Ô∏è  Prediction for {log_entry['Prediction_ID']} already exists. Skipping log.\")\n",
        "                return\n",
        "            log_df = pd.concat([log_df, new_log_df], ignore_index=True)\n",
        "        else:\n",
        "            log_df = new_log_df\n",
        "\n",
        "        log_df.to_csv(log_file, index=False)\n",
        "        print(f\"‚úÖ Prediction logged: {log_entry['Prediction_ID']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Failed to log prediction: {e}\")\n",
        "\n",
        "\n",
        "def update_prediction_with_actuals(player_name, game_date, actual_stats):\n",
        "    \"\"\"Updates a prediction log with actual game results.\"\"\"\n",
        "    log_file = cache_path(\"prediction_log.csv\")\n",
        "\n",
        "    if not os.path.exists(log_file):\n",
        "        print(\"‚ùå No prediction log found.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        log_df = pd.read_csv(log_file)\n",
        "        prediction_id = f\"{player_name}_{game_date.strftime('%Y%m%d')}\"\n",
        "\n",
        "        mask = log_df['Prediction_ID'] == prediction_id\n",
        "\n",
        "        if not mask.any():\n",
        "            print(f\"‚ùå No prediction found for {prediction_id}\")\n",
        "            return False\n",
        "\n",
        "        # Update actual values\n",
        "        for stat, value in actual_stats.items():\n",
        "            if f\"Actual_{stat}\" in log_df.columns:\n",
        "                log_df.loc[mask, f\"Actual_{stat}\"] = value\n",
        "\n",
        "        log_df.loc[mask, 'Status'] = 'COMPLETED'\n",
        "        log_df.loc[mask, 'Updated_At'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        log_df.to_csv(log_file, index=False)\n",
        "        print(f\"‚úÖ Updated actuals for {prediction_id}\")\n",
        "\n",
        "        # Calculate and display accuracy\n",
        "        row = log_df[mask].iloc[0]\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"üìä PREDICTION vs ACTUAL for {player_name}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for stat in STATS_TO_PREDICT:\n",
        "            pred_col = f\"Pred_{stat}\"\n",
        "            actual_col = f\"Actual_{stat}\"\n",
        "\n",
        "            if pred_col in row and actual_col in row and pd.notna(row[pred_col]) and pd.notna(row[actual_col]):\n",
        "                pred = row[pred_col]\n",
        "                actual = row[actual_col]\n",
        "                error = actual - pred\n",
        "                pct_error = (error / (actual + 1e-6)) * 100\n",
        "\n",
        "                # Check if within confidence interval\n",
        "                lower = row.get(f\"Pred_{stat}_Lower\", pred)\n",
        "                upper = row.get(f\"Pred_{stat}_Upper\", pred)\n",
        "                in_ci = \"‚úÖ\" if lower <= actual <= upper else \"‚ùå\"\n",
        "\n",
        "                print(f\"{stat:5} | Pred: {pred:5.1f} | Actual: {actual:5.1f} | \" +\n",
        "                      f\"Error: {error:+5.1f} ({pct_error:+.0f}%) | In 95% CI: {in_ci}\")\n",
        "\n",
        "        print(\"=\"*60)\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error updating actuals: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def fetch_actual_stats_for_game(player_name, game_date):\n",
        "    \"\"\"\n",
        "    Fetches actual game stats for a player on a specific date.\n",
        "    Returns dict of actual stats or None if not found.\n",
        "    \"\"\"\n",
        "    player_id = get_player_id(player_name)\n",
        "    if not player_id:\n",
        "        return None\n",
        "\n",
        "    # Determine which season the game_date falls in\n",
        "    game_year = game_date.year\n",
        "    if game_date.month >= 10:  # Oct-Dec\n",
        "        season = f\"{game_year}-{str(game_year + 1)[-2:]}\"\n",
        "    else:  # Jan-Sep\n",
        "        season = f\"{game_year - 1}-{str(game_year)[-2:]}\"\n",
        "\n",
        "    print(f\"Fetching actual stats for {player_name} on {game_date.strftime('%Y-%m-%d')}...\")\n",
        "\n",
        "    try:\n",
        "        gamelog_df = fetch_player_gamelogs(player_id, [season])\n",
        "\n",
        "        if gamelog_df.empty:\n",
        "            print(\"No gamelogs found.\")\n",
        "            return None\n",
        "\n",
        "        # Find the game on the specific date\n",
        "        # Need to convert GAME_DATE to date() for comparison\n",
        "        game_row = gamelog_df[gamelog_df['GAME_DATE'].dt.date == game_date.date()]\n",
        "\n",
        "        if game_row.empty:\n",
        "            print(f\"No game found on {game_date.strftime('%Y-%m-%d')}\")\n",
        "            return None\n",
        "\n",
        "        game = game_row.iloc[0]\n",
        "\n",
        "        # Calculate PRA\n",
        "        pra = game['PTS'] + game['REB'] + game['AST']\n",
        "\n",
        "        actual_stats = {\n",
        "            'PTS': game['PTS'],\n",
        "            'REB': game['REB'],\n",
        "            'AST': game['AST'],\n",
        "            'STL': game['STL'],\n",
        "            'BLK': game['BLK'],\n",
        "            'MIN': game['MIN'],\n",
        "            'FG3M': game['FG3M'],\n",
        "            'PRA': pra\n",
        "        }\n",
        "\n",
        "        print(f\"‚úÖ Found actual stats for game on {game_date.strftime('%Y-%m-%d')}\")\n",
        "        return actual_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching actual stats: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def auto_update_pending_predictions(player_name=None):\n",
        "    \"\"\"\n",
        "    Automatically checks for pending predictions and updates them with actuals.\n",
        "    If player_name is provided, only updates that player's predictions.\n",
        "    \"\"\"\n",
        "    log_file = cache_path(\"prediction_log.csv\")\n",
        "\n",
        "    if not os.path.exists(log_file):\n",
        "        print(\"No prediction log found.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        log_df = pd.read_csv(log_file)\n",
        "\n",
        "        # Filter for pending predictions\n",
        "        pending = log_df[log_df['Status'] == 'PENDING'].copy()\n",
        "\n",
        "        if player_name:\n",
        "            pending = pending[pending['Player_Name'].str.lower() == player_name.lower()]\n",
        "\n",
        "        if pending.empty:\n",
        "            print(\"No pending predictions to update.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Found {len(pending)} pending prediction(s) to update\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        for idx, row in pending.iterrows():\n",
        "            pred_player = row['Player_Name']\n",
        "            pred_date = pd.to_datetime(row['Game_Date'])\n",
        "\n",
        "            # Only update if game date has passed\n",
        "            if pred_date.date() > datetime.now().date():\n",
        "                print(f\"‚è≥ {pred_player} vs {row['Opponent']} on {pred_date.strftime('%Y-%m-%d')} - Game hasn't occurred yet\")\n",
        "                continue\n",
        "\n",
        "            print(f\"üîÑ Updating: {pred_player} vs {row['Opponent']} on {pred_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            actual_stats = fetch_actual_stats_for_game(pred_player, pred_date)\n",
        "\n",
        "            if actual_stats:\n",
        "                update_prediction_with_actuals(pred_player, pred_date, actual_stats)\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  Could not fetch actuals for {pred_player} on {pred_date.strftime('%Y-%m-%d')}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in auto-update: {e}\")\n",
        "\n",
        "\n",
        "def generate_accuracy_report(player_name=None, min_predictions=5):\n",
        "    \"\"\"\n",
        "    Generates a comprehensive accuracy report from completed predictions.\n",
        "    \"\"\"\n",
        "    log_file = cache_path(\"prediction_log.csv\")\n",
        "\n",
        "    if not os.path.exists(log_file):\n",
        "        print(\"‚ùå No prediction log found. Make predictions first!\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        log_df = pd.read_csv(log_file)\n",
        "\n",
        "        # Filter for completed predictions\n",
        "        completed = log_df[log_df['Status'] == 'COMPLETED'].copy()\n",
        "\n",
        "        if player_name:\n",
        "            completed = completed[completed['Player_Name'].str.lower() == player_name.lower()]\n",
        "\n",
        "        if len(completed) < min_predictions:\n",
        "            print(f\"‚ö†Ô∏è  Only {len(completed)} completed prediction(s). Need at least {min_predictions} for meaningful analysis.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"üìà ACCURACY REPORT - {len(completed)} Completed Predictions\")\n",
        "        if player_name:\n",
        "            print(f\"Player: {player_name}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Calculate metrics for each stat\n",
        "        results = []\n",
        "\n",
        "        for stat in STATS_TO_PREDICT:\n",
        "            pred_col = f\"Pred_{stat}\"\n",
        "            actual_col = f\"Actual_{stat}\"\n",
        "            lower_col = f\"Pred_{stat}_Lower\"\n",
        "            upper_col = f\"Pred_{stat}_Upper\"\n",
        "\n",
        "            if pred_col not in completed.columns or actual_col not in completed.columns:\n",
        "                continue\n",
        "\n",
        "            # Remove rows with missing data\n",
        "            valid = completed[[pred_col, actual_col]].dropna()\n",
        "\n",
        "            if len(valid) == 0:\n",
        "                continue\n",
        "\n",
        "            predictions = valid[pred_col].values\n",
        "            actuals = valid[actual_col].values\n",
        "\n",
        "            # Calculate metrics\n",
        "            mae = mean_absolute_error(actuals, predictions)\n",
        "            medae = median_absolute_error(actuals, predictions)\n",
        "\n",
        "            # Mean Absolute Percentage Error\n",
        "            mape = np.mean(np.abs((actuals - predictions) / (actuals + 1e-6))) * 100\n",
        "\n",
        "            # Confidence interval coverage (if available)\n",
        "            ci_coverage = None\n",
        "            if lower_col in completed.columns and upper_col in completed.columns:\n",
        "                ci_valid = completed[[actual_col, lower_col, upper_col]].dropna()\n",
        "                if len(ci_valid) > 0:\n",
        "                    in_ci = ((ci_valid[actual_col] >= ci_valid[lower_col]) &\n",
        "                             (ci_valid[actual_col] <= ci_valid[upper_col]))\n",
        "                    ci_coverage = in_ci.sum() / len(ci_valid) * 100\n",
        "\n",
        "            # Calculate baseline (season average)\n",
        "            season_avg = actuals.mean()\n",
        "            baseline_mae = mean_absolute_error(actuals, [season_avg] * len(actuals))\n",
        "\n",
        "            # --- FIX: Handle baseline_mae == 0 ---\n",
        "            if baseline_mae == 0:\n",
        "                improvement = 0.0\n",
        "            else:\n",
        "                improvement = ((baseline_mae - mae) / baseline_mae) * 100\n",
        "            # --- END FIX ---\n",
        "\n",
        "            results.append({\n",
        "                'Stat': stat,\n",
        "                'Count': len(valid),\n",
        "                'MAE': mae,\n",
        "                'MedAE': medae,\n",
        "                'MAPE': mape,\n",
        "                'Baseline_MAE': baseline_mae,\n",
        "                'Improvement': improvement,\n",
        "                'CI_Coverage': ci_coverage\n",
        "            })\n",
        "\n",
        "        # Display results table\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        print(f\"\\n{'Stat':<6} {'Count':<7} {'MAE':<7} {'MedAE':<7} {'MAPE':<8} \" +\n",
        "              f\"{'Base MAE':<10} {'Improv':<9} {'CI Cov':<8}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for _, row in results_df.iterrows():\n",
        "            ci_str = f\"{row['CI_Coverage']:.1f}%\" if pd.notna(row['CI_Coverage']) else \"N/A\"\n",
        "            print(f\"{row['Stat']:<6} {row['Count']:<7} {row['MAE']:<7.2f} {row['MedAE']:<7.2f} \" +\n",
        "                  f\"{row['MAPE']:<7.1f}% {row['Baseline_MAE']:<10.2f} \" +\n",
        "                  f\"{row['Improvement']:+7.1f}% {ci_str:<8}\")\n",
        "\n",
        "        # Overall summary\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìä SUMMARY\")\n",
        "        print(\"=\"*70)\n",
        "        avg_improvement = results_df['Improvement'].mean()\n",
        "        avg_ci_coverage = results_df['CI_Coverage'].dropna().mean() if not results_df['CI_Coverage'].dropna().empty else None\n",
        "\n",
        "        print(f\"Average Improvement over Baseline: {avg_improvement:+.1f}%\")\n",
        "        if avg_ci_coverage:\n",
        "            print(f\"Average 95% CI Coverage: {avg_ci_coverage:.1f}% (Target: 95%)\")\n",
        "            if abs(avg_ci_coverage - 95) < 5:\n",
        "                print(\"‚úÖ Confidence intervals well-calibrated!\")\n",
        "            elif avg_ci_coverage < 90:\n",
        "                print(\"‚ö†Ô∏è  Confidence intervals may be too narrow (underconfident)\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è  Confidence intervals may be too wide (overconfident)\")\n",
        "\n",
        "        # Best and worst performing stats\n",
        "        best_stat = results_df.loc[results_df['Improvement'].idxmax()]\n",
        "        worst_stat = results_df.loc[results_df['Improvement'].idxmin()]\n",
        "\n",
        "        print(f\"\\nüèÜ Best Prediction: {best_stat['Stat']} ({best_stat['Improvement']:+.1f}% improvement)\")\n",
        "        print(f\"üìâ Needs Work: {worst_stat['Stat']} ({worst_stat['Improvement']:+.1f}% improvement)\")\n",
        "\n",
        "        # Recent performance trend\n",
        "        if len(completed) >= 10:\n",
        "            recent_5 = completed.tail(5)\n",
        "            older_5 = completed.iloc[-10:-5] if len(completed) >= 10 else completed.iloc[:-5]\n",
        "\n",
        "            print(f\"\\nüìà RECENT TREND (Last 5 vs Previous 5 predictions)\")\n",
        "            for stat in STATS_TO_PREDICT:\n",
        "                pred_col = f\"Pred_{stat}\"\n",
        "                actual_col = f\"Actual_{stat}\"\n",
        "\n",
        "                if pred_col in recent_5.columns and actual_col in recent_5.columns:\n",
        "                    recent_valid = recent_5[[pred_col, actual_col]].dropna()\n",
        "                    older_valid = older_5[[pred_col, actual_col]].dropna()\n",
        "\n",
        "                    if len(recent_valid) > 0 and len(older_valid) > 0:\n",
        "                        recent_mae = mean_absolute_error(recent_valid[actual_col], recent_valid[pred_col])\n",
        "                        older_mae = mean_absolute_error(older_valid[actual_col], older_valid[pred_col])\n",
        "\n",
        "                        trend = \"üìà\" if recent_mae < older_mae else \"üìâ\"\n",
        "                        print(f\"{stat}: Recent MAE {recent_mae:.2f} vs Old MAE {older_mae:.2f} {trend}\")\n",
        "\n",
        "        # --- FIX: Corrected the stray text in the print statement ---\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "        # --- END FIX ---\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating report: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# --- Prediction with Confidence Intervals ---\n",
        "def predict_next_game(player_name, seasons, next_opp_abbr, is_home, days_rest, player_df=None):\n",
        "    player_id = get_player_id(player_name)\n",
        "    if player_id is None:\n",
        "        print(f\"Error: Player '{player_name}' not found.\")\n",
        "        return None, None\n",
        "\n",
        "    if player_df is None:\n",
        "        player_df = fetch_player_gamelogs(player_id, seasons)\n",
        "        if player_df.empty:\n",
        "            return None, None\n",
        "\n",
        "    team_stats_dict = fetch_all_team_defensive_stats(seasons)\n",
        "    if not team_stats_dict:\n",
        "        return None, None\n",
        "\n",
        "    feature_df = create_features(player_df, team_stats_dict)\n",
        "    if feature_df.empty:\n",
        "        return None, None\n",
        "\n",
        "    # Exclude non-features\n",
        "    exclude_cols = [col for col in feature_df.columns if\n",
        "                    col.startswith('TARGET_') or col in BASE_PLAYER_FEATURES or\n",
        "                    col in ['Game_ID', 'GAME_DATE', 'MATCHUP', 'WL', 'SEASON_ID',\n",
        "                            'OPP_ABBR', 'TEAM_ID', 'TEAM_ABBREVIATION', 'Player_ID',\n",
        "                            'VIDEO_AVAILABLE'] or '_DROP' in col]\n",
        "\n",
        "    feature_columns = [col for col in feature_df.columns if col not in exclude_cols]\n",
        "    X_all = feature_df[feature_columns]\n",
        "\n",
        "    prediction_features_df = create_prediction_features(\n",
        "        player_df, team_stats_dict, next_opp_abbr, is_home, days_rest\n",
        "    )\n",
        "\n",
        "    if prediction_features_df is None:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        prediction_features_df = prediction_features_df[feature_columns]\n",
        "    except KeyError as e:\n",
        "        print(f\"Feature mismatch: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    final_predictions = {}\n",
        "    all_metrics = {}\n",
        "\n",
        "    for stat in STATS_TO_PREDICT:\n",
        "        y = feature_df[f'TARGET_{stat}']\n",
        "\n",
        "        model, features_used, metrics = train_model_with_validation(X_all, y, stat)\n",
        "\n",
        "        if model and features_used:\n",
        "            X_pred = prediction_features_df[features_used]\n",
        "            prediction = model.predict(X_pred)[0]\n",
        "\n",
        "            # Add confidence interval\n",
        "            std_error = metrics['std_error']\n",
        "            lower_bound = max(0, prediction - 1.96 * std_error)  # 95% CI\n",
        "            upper_bound = prediction + 1.96 * std_error\n",
        "\n",
        "            final_predictions[stat] = {\n",
        "                'prediction': max(0, round(float(prediction), 2)),\n",
        "                'lower_95': round(float(lower_bound), 2),\n",
        "                'upper_95': round(float(upper_bound), 2),\n",
        "                'std_error': round(float(std_error), 2),\n",
        "                'model_mae': round(metrics.get('mae', 0), 2),\n",
        "                'model_r2': round(metrics.get('r2', 0), 3),\n",
        "                'model_improvement': round(metrics.get('improvement_pct', 0), 1)\n",
        "            }\n",
        "            all_metrics[stat] = metrics\n",
        "        else:\n",
        "            final_predictions[stat] = None\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"üéØ PREDICTIONS FOR {player_name}\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Matchup: {('HOME' if is_home else 'AWAY')} vs. {next_opp_abbr} (Rest: {days_rest} days)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for stat in ['MIN', 'PRA'] + [s for s in STATS_TO_PREDICT if s not in ['MIN', 'PRA']]:\n",
        "        if stat in final_predictions and final_predictions[stat]:\n",
        "            pred = final_predictions[stat]\n",
        "            print(f\"{stat:5} | Prediction: {pred['prediction']:5.1f} | \" +\n",
        "                  f\"95% CI: [{pred['lower_95']:5.1f}, {pred['upper_95']:5.1f}] | \" +\n",
        "                  f\"¬±{pred['std_error']:.1f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return final_predictions, all_metrics\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- !! MODIFY THIS !! ---\n",
        "     # This is now the ONLY input\n",
        "    # --- !! END MODIFY !! ---\n",
        "\n",
        "    # 1. Auto-detect seasons\n",
        "    SEASONS_TO_TRAIN = get_training_seasons()\n",
        "\n",
        "    # 2. Auto-detect next game\n",
        "    print(f\"\\n--- Attempting to auto-detect next game for {PLAYER_NAME} ---\")\n",
        "\n",
        "    NEXT_OPPONENT_ABBR = None\n",
        "    IS_NEXT_GAME_HOME = None\n",
        "    DAYS_REST_BEFORE_GAME = None\n",
        "    player_df_for_rest = None\n",
        "    next_game_date = None\n",
        "    found_game_flag = False\n",
        "\n",
        "    try:\n",
        "        player_id = get_player_id(PLAYER_NAME)\n",
        "        if player_id is None:\n",
        "            raise ValueError(f\"Player '{PLAYER_NAME}' not found.\")\n",
        "\n",
        "        player_df_for_rest = fetch_player_gamelogs(player_id, SEASONS_TO_TRAIN)\n",
        "        if player_df_for_rest.empty:\n",
        "            raise ValueError(f\"No gamelogs found for {PLAYER_NAME}.\")\n",
        "\n",
        "        # --- FIX: Find the last game *actually played* ---\n",
        "        today_date = pd.to_datetime(datetime.now().date())\n",
        "        played_games = player_df_for_rest[player_df_for_rest['GAME_DATE'] < today_date]\n",
        "        if played_games.empty:\n",
        "            raise ValueError(f\"No *past* gamelogs found for {PLAYER_NAME} to calculate rest.\")\n",
        "        last_game_date = played_games.iloc[-1]['GAME_DATE']\n",
        "        # --- END FIX ---\n",
        "\n",
        "        print(\"Fetching next game details (Method 1: PlayerProfile)...\")\n",
        "        profile_dfs = fetch_with_retry_all_dfs(\n",
        "            playerprofilev2.PlayerProfileV2,\n",
        "            player_id=player_id\n",
        "        )\n",
        "\n",
        "        overview_df = profile_dfs[0] if len(profile_dfs) > 0 else pd.DataFrame()\n",
        "        next_game_df = profile_dfs[1] if len(profile_dfs) > 1 else pd.DataFrame()\n",
        "\n",
        "        player_team_id = None\n",
        "        player_team_abbr = None\n",
        "\n",
        "        if overview_df.empty:\n",
        "            print(\"Warning: PlayerProfile overview is empty. Getting team from last gamelog.\")\n",
        "            last_game_matchup = player_df_for_rest.iloc[-1]['MATCHUP']\n",
        "            player_team_abbr = last_game_matchup.split(' ')[0]\n",
        "            player_team_id = get_team_id(player_team_abbr)\n",
        "            if player_team_id is None:\n",
        "                raise ValueError(f\"Could not determine Team ID for {player_team_abbr}\")\n",
        "        else:\n",
        "            player_team_id = overview_df.iloc[0]['TEAM_ID']\n",
        "            player_team_abbr = overview_df.iloc[0]['TEAM_ABBREVIATION']\n",
        "        print(f\"Player's team identified as: {player_team_abbr} (ID: {player_team_id})\")\n",
        "\n",
        "        if not next_game_df.empty:\n",
        "            print(\"‚úÖ Found game via PlayerProfile.\")\n",
        "            next_game = next_game_df.iloc[0]\n",
        "            next_game_date = pd.to_datetime(next_game['GAME_DATE'])\n",
        "\n",
        "            if player_team_id == next_game['HOME_TEAM_ID']:\n",
        "                IS_NEXT_GAME_HOME = True\n",
        "                NEXT_OPPONENT_ABBR = next_game['VISITOR_TEAM_ABBREVIATION']\n",
        "            else:\n",
        "                IS_NEXT_GAME_HOME = False\n",
        "                NEXT_OPPONENT_ABBR = next_game['HOME_TEAM_ABBREVIATION']\n",
        "\n",
        "            DAYS_REST_BEFORE_GAME = (next_game_date - last_game_date).days\n",
        "            found_game_flag = True\n",
        "\n",
        "        else:\n",
        "            print(f\"Warning: PlayerProfile shows no upcoming game. Trying scoreboard...\")\n",
        "\n",
        "            server_today_dt = datetime.now().date()\n",
        "            server_yesterday_dt = server_today_dt - timedelta(days=1)\n",
        "            check_dates = [server_yesterday_dt, server_today_dt]\n",
        "\n",
        "            for check_date in check_dates:\n",
        "                if found_game_flag: break\n",
        "                check_date_str = check_date.strftime('%m/%d/%Y')\n",
        "                print(f\"Checking scoreboard for {check_date_str}...\")\n",
        "                game_headers = pd.DataFrame()\n",
        "                try:\n",
        "                    game_headers = fetch_with_retry(\n",
        "                        scoreboardv2.ScoreboardV2,\n",
        "                        game_date=check_date_str\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(f\"No games found on {check_date_str}.\")\n",
        "\n",
        "                if not game_headers.empty:\n",
        "                    for idx, game in game_headers.iterrows():\n",
        "                        if str(game['HOME_TEAM_ID']) == str(player_team_id):\n",
        "                            IS_NEXT_GAME_HOME = True\n",
        "                            NEXT_OPPONENT_ABBR = get_team_abbr(game['VISITOR_TEAM_ID'])\n",
        "                            next_game_date = pd.to_datetime(game['GAME_DATE_EST'])\n",
        "                            found_game_flag = True\n",
        "                            break\n",
        "                        elif str(game['VISITOR_TEAM_ID']) == str(player_team_id):\n",
        "                            IS_NEXT_GAME_HOME = False\n",
        "                            NEXT_OPPONENT_ABBR = get_team_abbr(game['HOME_TEAM_ID'])\n",
        "                            next_game_date = pd.to_datetime(game['GAME_DATE_EST'])\n",
        "                            found_game_flag = True\n",
        "                            break\n",
        "\n",
        "                if found_game_flag:\n",
        "                    DAYS_REST_BEFORE_GAME = (next_game_date - last_game_date).days\n",
        "                    break\n",
        "\n",
        "            if not found_game_flag:\n",
        "                raise ValueError(f\"No upcoming game found for {player_team_abbr}.\")\n",
        "\n",
        "        print(f\"‚úÖ Auto-detected matchup: {('HOME' if IS_NEXT_GAME_HOME else 'AWAY')} vs. {NEXT_OPPONENT_ABBR}\")\n",
        "        print(f\"‚úÖ Auto-detected rest: {DAYS_REST_BEFORE_GAME} days (Last: {last_game_date.date()}, Next: {next_game_date.date()})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå FATAL ERROR during auto-detection: {e}\")\n",
        "        print(\"Cannot proceed without next game details.\")\n",
        "\n",
        "    # 3. Make prediction if we have all the info\n",
        "    if all([NEXT_OPPONENT_ABBR, IS_NEXT_GAME_HOME is not None, DAYS_REST_BEFORE_GAME is not None,\n",
        "            player_df_for_rest is not None and not player_df_for_rest.empty]):\n",
        "        try:\n",
        "            predictions, metrics = predict_next_game(\n",
        "                PLAYER_NAME,\n",
        "                SEASONS_TO_TRAIN,\n",
        "                NEXT_OPPONENT_ABBR,\n",
        "                IS_NEXT_GAME_HOME,\n",
        "                DAYS_REST_BEFORE_GAME,\n",
        "                player_df=player_df_for_rest\n",
        "            )\n",
        "\n",
        "            if predictions and next_game_date:\n",
        "                # Log prediction\n",
        "                log_prediction_to_csv(\n",
        "                    PLAYER_NAME,\n",
        "                    next_game_date,\n",
        "                    NEXT_OPPONENT_ABBR,\n",
        "                    IS_NEXT_GAME_HOME,\n",
        "                    DAYS_REST_BEFORE_GAME,\n",
        "                    predictions\n",
        "                )\n",
        "\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"üîß BACKTESTING TOOLS\")\n",
        "                print(\"=\"*60)\n",
        "                print(\"To update this prediction with actual results after the game:\")\n",
        "                print(f\"  auto_update_pending_predictions('{PLAYER_NAME}')\")\n",
        "                print(\"\\nTo generate accuracy report:\")\n",
        "                print(f\"  generate_accuracy_report('{PLAYER_NAME}')\")\n",
        "                print(\"=\"*60)\n",
        "\n",
        "            else:\n",
        "                print(\"\\n‚ùå Prediction failed during model training.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "    else:\n",
        "        print(\"\\n‚ùå Skipping prediction - auto-detection failed.\")\n",
        "\n",
        "    # 4. Optionally auto-update any pending predictions\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üîÑ Checking for pending predictions to update...\")\n",
        "    print(\"=\"*60)\n",
        "    auto_update_pending_predictions(PLAYER_NAME)\n",
        "\n",
        "    # 5. Show accuracy report if we have enough data\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä Generating Accuracy Report...\")\n",
        "    print(\"=\"*60)\n",
        "    generate_accuracy_report(PLAYER_NAME, min_predictions=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zfj80OQXYN27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install nba_api\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khgu2RiVFrTh",
        "outputId": "721c6af7-c7cf-4219-e969-6bb8775fba9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nba_api\n",
            "  Downloading nba_api-1.10.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nba_api) (1.17.0)\n",
            "Downloading nba_api-1.10.2-py3-none-any.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m287.0/287.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nba_api\n",
            "Successfully installed nba_api-1.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5byPEEgUxlX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}